{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7071c89b-796c-4921-8dfb-a7f3942ae677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing RAG system... This may take a minute.\n",
      "Processed MDD: 724 chunks.\n",
      "Processed MDR: 2795 chunks.\n",
      "RAG system initialized successfully in 17.71 seconds.\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://a7be6ff73162c9686d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a7be6ff73162c9686d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Received question: What are the most significant new clinical evaluation requirements for a Class IIa device to be compliant with the MDR?\n",
      "Successfully generated response from LLM.\n",
      "\n",
      "Received question: What are the new requirements for the Unique Device Identification (UDI) system under the MDR, and how does this compare to the MDD?\n",
      "Successfully generated response from LLM.\n",
      "\n",
      "Received question: What are the most significant new clinical evaluation requirements for a Class IIa device to be compliant with the MDR?\n",
      "Successfully generated response from LLM.\n",
      "\n",
      "Received question: What does the MDR in Article 83 require for a manufacturer's post-market surveillance system, and what is the equivalent requirement in the MDD?\n",
      "Successfully generated response from LLM.\n",
      "\n",
      "Received question: Describe the general requirements for a clinical evaluation as outlined in MDR Annex XIV, Part A, and compare them to the clinical data requirements in MDD Annex X. \n",
      "Successfully generated response from LLM.\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://a7be6ff73162c9686d.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import chromadb\n",
    "import uuid\n",
    "from pypdf import PdfReader\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "# Configure the generative AI model \n",
    "load_dotenv() #loads the API key put in a .env file\n",
    "try:\n",
    "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Google AI. Please ensure your API key is correct. Error: {e}\")\n",
    "\n",
    "# Define file paths for your documents\n",
    "current_dir = os.getcwd() \n",
    "FILE_PATH_MDD = os.path.join(current_dir, '..', 'documents', 'MDD.txt')\n",
    "FILE_PATH_MDR = os.path.join(current_dir, '..', 'documents', 'MDR.txt')\n",
    "COLLECTION_NAME = \"mdr_gap_analysis_txt\"\n",
    "\n",
    "# Data processing function. Uses a smart logic to skip short paragraph \n",
    "# while maintaining titles and proximity between titles and the related paragraph.\n",
    "def process_txt_file(file_path, source_name):\n",
    "    \"\"\"\n",
    "    Reads a .txt file and splits it into chunks based on paragraphs\n",
    "    (separated by double newlines).\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the .txt file.\n",
    "        source_name (str): The name of the source document for metadata.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists: (text_chunks, metadatas).\n",
    "    \"\"\"\n",
    "    all_text_chunks = []\n",
    "    all_metadatas = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            full_text = f.read()\n",
    "\n",
    "        # Chunking strategy: split by double newline (a common paragraph separator)\n",
    "        paragraphs = full_text.split('\\n\\n')\n",
    "\n",
    "        for para in paragraphs:\n",
    "            stripped_para = para.strip()\n",
    "            if len(stripped_para) > 25:  # Filter out very short or empty lines\n",
    "                all_text_chunks.append(stripped_para)\n",
    "                # Metadata is simpler for a txt file, just the source\n",
    "                all_metadatas.append({'source': source_name})\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {file_path}: {e}\")\n",
    "\n",
    "    return all_text_chunks, all_metadatas\n",
    "\n",
    "# Initialize the RAG System (Vector Database with ChromaDB)\n",
    "\n",
    "print(\"Initializing RAG system... This may take a minute.\")\n",
    "start_time = time.time()\n",
    "client = chromadb.Client()\n",
    "#client = chromadb.PersistentClient(path=\"chroma_db_txt\")\n",
    "\n",
    "# Define the local embedding function (Chroma actually have its own default, but Sentence Transformer seems good)\n",
    "from chromadb.utils import embedding_functions\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Delete the collection if it already exists to ensure a fresh start and create the new one\n",
    "if COLLECTION_NAME in [c.name for c in client.list_collections()]:\n",
    "    client.delete_collection(name=COLLECTION_NAME)\n",
    "    print(f\"Deleted existing collection: {COLLECTION_NAME}\")\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=sentence_transformer_ef\n",
    ")\n",
    "\n",
    "# Process and load both documents into the database\n",
    "try:\n",
    "    chunks_mdd, metas_mdd = process_txt_file(FILE_PATH_MDD, 'MDD 93/42/EEC')\n",
    "    print(f\"Processed MDD: {len(chunks_mdd)} chunks.\")\n",
    "\n",
    "    chunks_mdr, metas_mdr = process_txt_file(FILE_PATH_MDR, 'MDR 2017/745')\n",
    "    print(f\"Processed MDR: {len(chunks_mdr)} chunks.\")\n",
    "\n",
    "    text_chunks = chunks_mdd + chunks_mdr\n",
    "    metadatas = metas_mdd + metas_mdr\n",
    "    collection.add(\n",
    "        ids=[str(uuid.uuid4()) for _ in text_chunks],\n",
    "        documents=text_chunks,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"RAG system initialized successfully in {end_time - start_time:.2f} seconds.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during initialization: {e}\")\n",
    "    collection = None\n",
    "\n",
    "# Core Function for Querying and Generation\n",
    "\n",
    "def get_gap_analysis(question): # The actual function called by Gradio at runtime\n",
    "    if not question or not question.strip():\n",
    "        return \"Please enter a question before submitting.\"\n",
    "    if not collection:\n",
    "        return \"Error: The RAG system is not initialized. Please check the file paths and restart the notebook.\"\n",
    "    \n",
    "    print(f\"\\nReceived question: {question}\")\n",
    "    \n",
    "    # Query the vector store to get relevant context from both documents\n",
    "    results = collection.query(query_texts=[question], include = [\"documents\", \"metadatas\", \"distances\"], n_results=10)\n",
    "\n",
    "    sources_markdown = \"### Sources Used for Analysis\\n\\n\"\n",
    "    retrieved_documents = results['documents'][0]\n",
    "    retrieved_metadatas = results['metadatas'][0]\n",
    "    retrieved_distances = results['distances'][0]\n",
    "\n",
    "    for i, (doc, meta, dist) in enumerate(zip(retrieved_documents, retrieved_metadatas, retrieved_distances)):\n",
    "        # Convert distance to a more intuitive similarity score (1 - distance)\n",
    "        relevance_score = 1 - dist\n",
    "        source_info = f\"**Source {i+1}:** {meta.get('source', 'N/A')}, Page {meta.get('page', 'N/A')}\\n\"\n",
    "        relevance_info = f\"**Relevance Score:** {relevance_score:.2f}\\n\\n\"\n",
    "        content_info = f\"```\\n{doc}\\n```\\n\\n---\\n\\n\"\n",
    "        sources_markdown += source_info + relevance_info + content_info\n",
    "            \n",
    "    # Separate the context by source\n",
    "    context_mdr = \"\"\n",
    "    context_mdd = \"\"\n",
    "    for doc, meta, distance in zip(retrieved_documents, retrieved_metadatas, retrieved_distances):\n",
    "        if meta.get('source') == 'MDR 2017/745':\n",
    "            context_mdr += f\"[Page {meta.get('page', 'N/A')}]: {doc}, distance: {distance}\\n\\n\"\n",
    "        elif meta.get('source') == 'MDD 93/42/EEC':\n",
    "            context_mdd += f\"[Page {meta.get('page', 'N/A')}]: {doc}, distance: {distance}\\n\\n\"\n",
    "\n",
    "    # Engineer the prompt for the LLM (mid complexity prompt)\n",
    "    prompt = f\"\"\"\n",
    "    Act as a Senior Regulatory Consultant for a MedTech company. Your task is to perform a gap analysis based on the user's question, using **exclusively** the provided context from two documents: the old Medical Device Directive (MDD) and the new Medical Device Regulation (MDR).\n",
    "\n",
    "    Follow this structure for your response:\n",
    "    1.  **Summary of MDD Requirements:** Based on the MDD context, briefly summarize the old requirements.\n",
    "    2.  **Summary of MDR Requirements:** Based on the MDR context, summarize the new, more demanding requirements.\n",
    "    3.  **Gap Analysis:** Clearly highlight the key differences and new obligations the company needs to address.\n",
    "    4.  **Strategic Recommendation:** Provide a concise, actionable recommendation.\n",
    "\n",
    "    **Crucial Rule:** If the context for one of the documents is missing or insufficient, state that clearly. Do not invent information.\n",
    "\n",
    "    ---\n",
    "    **CONTEXT FROM MDD 93/42/EEC:**\n",
    "    {context_mdd if context_mdd else \"No specific context retrieved.\"}\n",
    "\n",
    "    ---\n",
    "    **CONTEXT FROM MDR 2017/745:**\n",
    "    {context_mdr if context_mdr else \"No specific context retrieved.\"}\n",
    "\n",
    "    ---\n",
    "    **USER QUESTION:** {question}\n",
    "\n",
    "    **CONSULTANT'S ANALYSIS:**\n",
    "    \"\"\"\n",
    "\n",
    "    # Call the LLM to generate the analysis\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        response = model.generate_content(prompt)\n",
    "        print(\"Successfully generated response from LLM.\")\n",
    "        return response.text, sources_markdown\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling the LLM: {e}\")\n",
    "        return f\"An error occurred while generating the response: {e}\"\n",
    "\n",
    "# Create and Launch the Gradio App\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# MDR Gap Analysis AI Companion\")\n",
    "    gr.Markdown(\"### Welcome.\\nPose your question below to analyze the regulatory differences between the MDD and MDR.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        question_input = gr.Textbox(\n",
    "            label=\"Your Question\",\n",
    "            placeholder=\"e.g., How have the requirements for post-market surveillance changed from the MDD to the MDR?\",\n",
    "            lines=3\n",
    "        )\n",
    "    \n",
    "    submit_button = gr.Button(\"Get Analysis!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        answer_output = gr.Markdown(label=\"Consultant's Analysis\")\n",
    "\n",
    "    with gr.Accordion(\"View Sources and Relevance Scores\", open=False):\n",
    "        sources_output = gr.Markdown(label=\"Retrieved Context\")\n",
    "        \n",
    "    # Define the examples to show in the UI\n",
    "    examples = [\n",
    "        \"How have the requirements for post-market surveillance changed from the MDD to the MDR?\",\n",
    "        \"What are the new requirements for the Unique Device Identification (UDI) system under the MDR, and how does this compare to the MDD?\",\n",
    "        \"What are the most significant new clinical evaluation requirements for a Class IIa device to be compliant with the MDR?\"\n",
    "    ]\n",
    "    gr.Examples(examples=examples, inputs=question_input)\n",
    "\n",
    "    # Link the button to the function\n",
    "    submit_button.click(\n",
    "        fn=get_gap_analysis,\n",
    "        inputs=question_input,\n",
    "        outputs=[answer_output, sources_output]\n",
    "    )\n",
    "\n",
    "# Launch the app. In a Jupyter Notebook, the interface will appear directly in the cell output.\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c7899a-ee39-4c38-8ed8-2db2fccfe1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
