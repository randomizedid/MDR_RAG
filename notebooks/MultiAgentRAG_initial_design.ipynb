{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb86a40c-00bd-4dfa-bd28-67dce3e720b1",
   "metadata": {},
   "source": [
    "### Multi-Agent RAG system\n",
    "This Jupyter Notebook serves as a proof of concept of a multi-agent solution for MedTech regulations. The intent of the system is to provide clear answers to questions on WHO and FDA documentations on medical devices, using a 3-to-4 agents system composed like this:\n",
    "\n",
    "- an LLM orchestrator that receives the question and coordinates agents\n",
    "- a RAG agent capable of retrieving documents related to the question\n",
    "- an LLM response agent to put together the answer based on the documents retrieved and the question\n",
    "- a possible fourth agent to be decided (chunking agent, source-verifier agent, compare agent, prompt agent to improve prompts, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae99977-325e-4a78-b556-a63ccb3dca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\npseudo code for multi agent system\\n\\nclass agent\\n\\ninstantiate orchestrator and other agents\\n\\ndefine orchestrator prompt and response false\\n\\ntake input\\n\\nwhile not response:\\n\\n    orchestrator call\\n\\n    designed agent call\\n\\nreturn response\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "pseudo code for multi agent system\n",
    "\n",
    "class agent\n",
    "\n",
    "instantiate orchestrator and other agents\n",
    "\n",
    "define orchestrator prompt and response false\n",
    "\n",
    "take input\n",
    "\n",
    "while not response:\n",
    "\n",
    "    orchestrator call\n",
    "\n",
    "    designed agent call\n",
    "\n",
    "return response\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40713cc2-97db-4577-a884-fd2fb1f081c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import chromadb\n",
    "import uuid\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pymupdf4llm\n",
    "import json\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30825fc5-b1f5-43de-a6e7-c9f0ce7f3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environmental variables and AI models\n",
    "\n",
    "load_dotenv() # load the API key and put in a .env file\n",
    "try:\n",
    "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Google AI. Please ensure your API key is correct. Error: {e}\")\n",
    "\n",
    "# Configure paths to data\n",
    "current_dir = os.getcwd() \n",
    "FILE_PATH_FDA_DESIGN = os.path.join(current_dir, '..', 'documents', 'FDA_Design_Control_Guidance.pdf')\n",
    "FILE_PATH_WHO = os.path.join(current_dir, '..', 'documents', 'WHO_Medical_Device_Regulations.pdf')\n",
    "FILE_PATH_FDA_POLICY = os.path.join(current_dir, '..', 'documents', 'FDA_Policy_Device_Software_Functions.pdf')\n",
    "COLLECTION_NAME = \"multi_agent_rag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d6997c9-03e2-4a41-8f6a-327a00857e83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1657 1657\n"
     ]
    }
   ],
   "source": [
    "# Split logic (very simple, splitting paragraphs and skipping short ones)\n",
    "\n",
    "def split_into_chunks(dict_list):\n",
    "    text_chunks = []\n",
    "    metadatas = []\n",
    "    \n",
    "    for document in dict_list:\n",
    "        try:\n",
    "            paragraphs = list(document.values())[0].split(\"\\n\\n\")\n",
    "    \n",
    "            for paragraph in paragraphs: # Delete short paragraphs\n",
    "                if len(paragraph) > 10:\n",
    "                    text_chunks.append(paragraph)\n",
    "                    metadatas.append({\"source\": list(document.keys())[0]})\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {list(document.keys())[0]}: {e}\")\n",
    "            \n",
    "    return text_chunks, metadatas\n",
    "\n",
    "# Use pymupdf4llm to convert pdf into text, adequately formatted. Using dicts to keep track of sources and add them to metadata while chunking\n",
    "fda_design_dict = {'FDA_Design_Control_Guidance.pdf': pymupdf4llm.to_markdown(FILE_PATH_FDA_DESIGN)}\n",
    "who_dict = {'WHO_Medical_Device_Regulations.pdf': pymupdf4llm.to_markdown(FILE_PATH_WHO)}\n",
    "fda_policy_dict = {'FDA_Policy_Device_Software_Functions.pdf': pymupdf4llm.to_markdown(FILE_PATH_FDA_POLICY)}\n",
    "\n",
    "text_chunks, metadatas = split_into_chunks([fda_design_dict, who_dict, fda_policy_dict])\n",
    "print(len(text_chunks), len(metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e7e25a2f-373c-4d86-917d-19c23ee619f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed FDA_Design: 67 chunks.\n",
      "Processed WHO: 120 chunks.\n",
      "Processed FDA Policy: 100 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Second chunking logic: texting up the documents. I'll convert the pdf in txt and see if the RAG handles them better.\n",
    "# Result: it worked worse.\n",
    "\n",
    "# Configure paths to data\n",
    "current_dir = os.getcwd() \n",
    "FILE_PATH_FDA_DESIGN = os.path.join(current_dir, '..', 'documents', 'FDA_Design_Control_Guidance.txt')\n",
    "FILE_PATH_WHO = os.path.join(current_dir, '..', 'documents', 'WHO_Medical_Device_Regulations.txt')\n",
    "FILE_PATH_FDA_POLICY = os.path.join(current_dir, '..', 'documents', 'FDA_Policy_Device_Software_Functions.txt')\n",
    "COLLECTION_NAME = \"multi_agent_rag\"\n",
    "\n",
    "def process_txt_file(file_path, source_name):\n",
    "    all_text_chunks = []\n",
    "    all_metadatas = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            full_text = f.read()\n",
    "\n",
    "        # Chunking strategy: split by paragraph\n",
    "        paragraphs = full_text.split('\\n\\n')\n",
    "\n",
    "        for para in paragraphs:\n",
    "            stripped_para = para.strip()\n",
    "            if len(stripped_para) > 25:  # Filter out very short paragraphs or empty lines\n",
    "                all_text_chunks.append(stripped_para)\n",
    "                # Metadata is simpler for a txt file, just the source\n",
    "                all_metadatas.append({'source': source_name})\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {file_path}: {e}\")\n",
    "\n",
    "    return all_text_chunks, all_metadatas\n",
    "\n",
    "chunks_fdad, metas_fdad = process_txt_file(FILE_PATH_FDA_DESIGN, 'FDA_Design_Control_Guidance')\n",
    "print(f\"Processed FDA_Design: {len(chunks_fdad)} chunks.\")\n",
    "\n",
    "chunks_who, metas_who = process_txt_file(FILE_PATH_WHO, 'WHO_Medical_Device_Regulations')\n",
    "print(f\"Processed WHO: {len(chunks_who)} chunks.\")\n",
    "\n",
    "chunks_fdap, metas_fdap = process_txt_file(FILE_PATH_FDA_POLICY, 'FDA_Policy_Device_Software_Functions')\n",
    "print(f\"Processed FDA Policy: {len(chunks_fdap)} chunks.\")\n",
    "\n",
    "text_chunks = chunks_fdad + chunks_who + chunks_fdapS\n",
    "metadatas = metas_fdad + metas_who + metas_fdap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "455b173f-006d-4f4a-8de5-e754aef4524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent classes. Every agent will have a memory variable with a memory limit, and this will be the context that gets passed along.\n",
    "# It would be cleaner to build a 'state' that every agent can access and update (similar to the logic of LangGraph), but this works fine for a POC.\n",
    "\n",
    "class OrchestratorAgent:\n",
    "\n",
    "    def __init__(self, agents):\n",
    "        self.agents = agents\n",
    "        self.memory = []\n",
    "        self.memory_limit = 15\n",
    "\n",
    "        self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        #self.model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')\n",
    "        self.generation_config = {\n",
    "            \"temperature\": 0.2,\n",
    "            \"top_k\": 10,\n",
    "            \"top_p\": 0.85,\n",
    "            \"max_output_tokens\": 8192\n",
    "        }\n",
    "\n",
    "    def run(self): # The main function, where the loop is. Keeps elaborating the input and calling an agent until the user cuts.\n",
    "        print(\"Hi! I am Camille, your MedTech regulatory companion. How can I help you?\")\n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "        while True:\n",
    "            self.memory = self.memory[-self.memory_limit:]\n",
    "            if user_input.lower() in [\"exit\", \"bye\", \"close\"]:\n",
    "                print(\"I hope I could be of use to you, have a great day!\")\n",
    "                break  \n",
    "            orch_response = self.orchestrate(user_input)\n",
    "            if orch_response[\"agent_to_call\"] == \"No action needed\":\n",
    "                print(\"Is there anything else I can help you with?\")\n",
    "                user_input = input(\"You: \")\n",
    "            for agent in self.agents:\n",
    "                if agent.name == orch_response[\"agent_to_call\"]:\n",
    "                    print(f\"Found agent I was looking for: {agent.name}\\n\")\n",
    "                    response = agent.act(orch_response[\"output\"], orch_response[\"relevant_info\"], self.memory)\n",
    "                    self.memory.append(f\"Agent {agent.name} responded {response}\")     \n",
    "        return response\n",
    "\n",
    "    def orchestrate(self, user_input):\n",
    "        self.memory.append(f\"User: {user_input}\")\n",
    "        self.memory = self.memory[-self.memory_limit:]\n",
    "        context = \"\\n\".join(self.memory)\n",
    "        response_format = {\"agent_to_call\":\"\", \"output\": \"\", \"relevant_info\":\"\"}\n",
    "        response = self.model.generate_content(self.get_prompt(context, response_format), generation_config = self.generation_config)\n",
    "        self.memory.append(f\"Orchestrator: {response.text}\")\n",
    "        response_cleaned = clean_response(response)\n",
    "        return response_cleaned\n",
    "\n",
    "    def get_prompt(self, context, response_format):\n",
    "        prompt = f\"\"\"\n",
    "        Act as an orchestrator agent for an intelligent RAG system for MedTech companies. Your task is to coordinate agents in order to extract relevant documents from a RAG system and package a coherent and precise answer to the query received.\n",
    "        The task is to call a first time the ragagent, and then use the ragagent documents to call the response_agent on them and craft a response. Make sure to call the response_agent if the history contains a previous call to the ragagent.\n",
    "        Your AI agents and their descriptions are {\", \".join([f\"- {agent.name}: {agent.description}\" for agent in self.agents])}\n",
    "\n",
    "        Use the context, which includes the current user input and the memory of previous inputs and outputs, to plan next steps.\n",
    "        Context : {context}\n",
    "\n",
    "        Guidelines:\n",
    "        At every step, you need to choose only one of the agents provide instruction to only that agent. If the request needs multiple agent to be solved, do that in a loop.\n",
    "        Read the context, take your time to understand the task, and check if you have executed it correctly.\n",
    "        If there are no actions needed, default the \"agent_to_call\" parameter to \"No action needed\" in the response.\n",
    "        Return only the agent name in the \"agent_to_call\" parameter.\n",
    "        You will return instructions in a valid JSON in the form of {response_format}. All output should be of string type, the \"output\" is for the query and the \"relevant_info\" is to attach documents from the RAG for the response agent.\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "class RAGAgent:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"ragagent\"\n",
    "        self.description = \"\"\"I am a RAG agent that can search for relevant documents in a vector database in order to answer a query.\n",
    "                            I expect a user query as input and will return relevant chunks and a variable containing sources info, relevance scores and chunks.\n",
    "                            \"\"\"\n",
    "        self.memory = []\n",
    "        self.memory_limit = 15\n",
    "        self.sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.collection_name = COLLECTION_NAME\n",
    "\n",
    "    def act(self, query, relevant_info, memory): # Checks whether the db exists before querying it.\n",
    "        if \"RAG initialized\" not in memory:\n",
    "            self.collection = self.initialize_db()\n",
    "            self.memory.append(\"RAG initialized\")\n",
    "        self.memory.append(memory)\n",
    "        self.memory = self.memory[-self.memory_limit:]\n",
    "        documents = self.query_db(query)\n",
    "        return documents\n",
    "\n",
    "    def initialize_db(self):\n",
    "        print(\"Initializing RAG system... This may take a minute.\")\n",
    "        self.client = chromadb.Client()\n",
    "\n",
    "        if self.collection_name in [c.name for c in self.client.list_collections()]:\n",
    "            self.client.delete_collection(name = self.collection_name)\n",
    "            #print(f\"Deleted existing collection: {self.collection_name}\"\n",
    "    \n",
    "        collection = self.client.get_or_create_collection(\n",
    "        name = self.collection_name,\n",
    "        embedding_function = self.sentence_transformer_ef\n",
    "        )\n",
    "        self.load_documents(collection, text_chunks, metadatas)\n",
    "\n",
    "        return collection\n",
    "\n",
    "    def load_documents(self, collection, document_chunks, metadatas):\n",
    "        collection.add(\n",
    "        ids = [str(uuid.uuid4()) for _ in text_chunks],\n",
    "        documents = text_chunks,\n",
    "        metadatas = metadatas)\n",
    "    \n",
    "    def query_db(self, question):\n",
    "        results = self.collection.query(query_texts=[question], include = [\"documents\", \"metadatas\", \"distances\"], n_results=5)\n",
    "\n",
    "        sources_markdown = \"### Sources Used for Analysis\\n\\n\"\n",
    "        retrieved_documents = results['documents'][0]\n",
    "        retrieved_metadatas = results['metadatas'][0]\n",
    "        retrieved_distances = results['distances'][0]\n",
    "    \n",
    "        for i, (doc, meta, dist) in enumerate(zip(retrieved_documents, retrieved_metadatas, retrieved_distances)):\n",
    "            # Convert distance to a more intuitive similarity score (1 - distance)\n",
    "            relevance_score = 1 - dist\n",
    "            source_info = f\"**Source {i+1}:** {meta.get('source', 'N/A')}, Page {meta.get('page', 'N/A')}\\n\"\n",
    "            relevance_info = f\"**Relevance Score:** {relevance_score:.2f}\\n\\n\"\n",
    "            content_info = f\"```\\n{doc}\\n```\\n\\n---\\n\\n\"\n",
    "            sources_markdown += source_info + relevance_info + content_info\n",
    "        print(f\"Sources, documents and relevance score: {sources_markdown}\")\n",
    "            \n",
    "        return sources_markdown\n",
    "\n",
    "class ResponseAgent:\n",
    "    def __init__(self):\n",
    "        self.name = \"response_agent\"\n",
    "        self.description = \"\"\"I am a response agent that expects as input a user query and relevant documents and info from a RAG search.\n",
    "                            My task is to craft a precise response for the user based on the provided documents. I will return a response text.\n",
    "                            \"\"\"\n",
    "\n",
    "        self.memory = []\n",
    "        self.memory_limit = 15\n",
    "        self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        #self.model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')\n",
    "        self.generation_config = {\n",
    "            \"temperature\": 0.2,\n",
    "            \"top_k\": 10,\n",
    "            \"top_p\": 0.85,\n",
    "            \"max_output_tokens\": 8192\n",
    "        }\n",
    "    \n",
    "    def act(self, query, relevant_info, memory):\n",
    "        prompt = self.get_prompt(query, relevant_info, memory)\n",
    "        response = self.model.generate_content(prompt, generation_config = self.generation_config)\n",
    "        print(response.text)\n",
    "        return response.text\n",
    "\n",
    "    def get_prompt(self, query, relevant_info, memory):\n",
    "        self.memory = self.memory[-self.memory_limit:]\n",
    "        prompt = f\"\"\"\n",
    "        Act as Camille, an AI companion acting as a Senior Consultant for medical devices. You receive a query from your client, and answer to it based on the relevant information you receive from the RAG system as document chunks.\n",
    "        Be precise, confident and do not make things up. If the context is not enough to provide a clear answer, state it.\n",
    "        Cite the documents and sources you receive as part of your input and provide strategic recommendation. The structure of your answer will be:\n",
    "        - Salutation telling who you are.\n",
    "        - Precise response to the query based on the documents received from the RAG.\n",
    "\n",
    "        As additional resources:\n",
    "        User input: {query}\n",
    "        Relevant documents with sources and relevance scores: {relevant_info}\n",
    "        Memory of previous inputs and info: {memory}\n",
    "        \"\"\"\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e34d4077-9071-4fb7-b4c6-2d7c39f0bc82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I am Camille, your MedTech regulatory companion. How can I help you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What are the design control requirements for verification and validation?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found agent I was looking for: ragagent\n",
      "\n",
      "Initializing RAG system... This may take a minute.\n",
      "Sources, documents and relevance score: ### Sources Used for Analysis\n",
      "\n",
      "**Source 1:** FDA_Design_Control_Guidance.pdf, Page N/A\n",
      "**Relevance Score:** 0.45\n",
      "\n",
      "```\n",
      "\n",
      "be performed by device manufacturers. Rather, the manufacturer should select and apply\n",
      "appropriate verification techniques based on the generally accepted practices for the\n",
      "technologies employed in their products. Many of these practices are an integral part of\n",
      "the development process, and are routinely performed by developers. The objective of\n",
      "design controls is to ensure adequate oversight by making verification activities explicit\n",
      "and measuring the thoroughness of their execution. Following are a few examples of\n",
      "verification methods and activities.\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Source 2:** FDA_Design_Control_Guidance.pdf, Page N/A\n",
      "**Relevance Score:** 0.43\n",
      "\n",
      "```\n",
      "\n",
      "  - Each manufacturer shall establish and maintain procedures for validating the device\n",
      "design.\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Source 3:** FDA_Design_Control_Guidance.pdf, Page N/A\n",
      "**Relevance Score:** 0.40\n",
      "\n",
      "```\n",
      "\n",
      "  - Each manufacturer shall establish and maintain procedures to ensure that the\n",
      "design requirements relating to a device are appropriate and address the intended\n",
      "use of the device, including the needs of the user and patient.\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Source 4:** FDA_Design_Control_Guidance.pdf, Page N/A\n",
      "**Relevance Score:** 0.40\n",
      "\n",
      "```\n",
      "\n",
      "**(2)** _Design Validation_ means establishing by objective evidence that device\n",
      "specifications conform with user needs and intended use(s).\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Source 5:** FDA_Design_Control_Guidance.pdf, Page N/A\n",
      "**Relevance Score:** 0.40\n",
      "\n",
      "```\n",
      "\n",
      "**(2)** _Design Validation_ means establishing by objective evidence that device\n",
      "specifications conform with user needs and intended use(s).\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Found agent I was looking for: response_agent\n",
      "\n",
      "Hello, I'm Camille, your AI Senior Consultant for medical devices.\n",
      "\n",
      "Based on the provided FDA Design Control Guidance document (FDA_Design_Control_Guidance.pdf), the design control requirements for verification and validation include:\n",
      "\n",
      "* **Manufacturers must establish and maintain procedures for validating the device design.**  This means establishing, through objective evidence, that device specifications conform to user needs and intended use (Source 2, Source 4, Source 5).\n",
      "\n",
      "* **Manufacturers must establish and maintain procedures to ensure that design requirements are appropriate and address the intended use of the device, including user and patient needs.** (Source 3).\n",
      "\n",
      "* **Verification activities must be explicit and their thoroughness measured.** Manufacturers should select and apply appropriate verification techniques based on generally accepted practices for the technologies used.  The objective is adequate oversight (Source 1).\n",
      "\n",
      "The provided text offers a high-level overview.  To provide more specific guidance on verification methods and activities, additional information on the specific device and its technologies is needed.  I recommend reviewing the complete FDA Design Control Guidance document for a comprehensive understanding of all requirements.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate agent objects\n",
    "\n",
    "def clean_response(response):\n",
    "    response_text = response.text\n",
    "    #print(f\"Cleaning response {response.text}\")\n",
    "    start_index = response_text.find(\"{\")\n",
    "    end_index = response_text.rfind(\"}\")\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        response_cleaned = json.loads(response_text[start_index : end_index + 1])\n",
    "        #print(f\"Response cleaned is {response_cleaned}\")\n",
    "        return response_cleaned\n",
    "    else:\n",
    "        return response_text\n",
    "\n",
    "ragagent = RAGAgent()\n",
    "response_agent = ResponseAgent()\n",
    "orchestrator = OrchestratorAgent([ragagent, response_agent])\n",
    "\n",
    "final_answer = None\n",
    "history = [] \n",
    "query1 = \"Is our AI-powered MRI analysis tool considered a medical device software?\"\n",
    "query2 = \"What are the design control requirements for verification and validation?\"\n",
    "query3 = \"Compare FDA and WHO approaches to risk management for medical devices\"\n",
    "query4 = \"What documentation is needed for a mobile app that monitors heart rate?\"\n",
    "count_rag = 0\n",
    "count_final = 0\n",
    "\n",
    "orchestrator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde820ce-0e23-4632-bba8-aa08b63e92bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263bcd6-d7e8-4566-9b6a-578686f4df6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89678ba-472f-4dea-92b8-f0378fcf9f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ea1f8-4a2b-4255-bcac-e5b23e55bc24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
